#!/usr/bin/env bash

##############
### Tricks ###
##############

# FILENAME SLICING #
echo before comment
: <<"END"
export filename="foo.bar.baz"

echo $filename       => "foo.bar.baz"
echo ${filename#*.}  => "bar.baz"
echo ${filename##*.} => "baz"

echo ${filename%%.*} => "foo"
echo ${filename%.*}  => "foo.bar"

gnu.org/software/bash/manual/html_node/Shell-Parameter-Expansion.html
END
echo after comment

###########
### CSV ###
###########

csv() {
    # Note: can be piped to syntax-highlighter like hicat etc

    column -s, -t <$1;
}

getcolumn() {
    # NOTE
    # `cut` acts differently in macOS vs Ubuntu
    # This example is for macOS, but Ubuntu's is the better one
    # You basically have do an inverse of the other OS version
    # More info at ndarville.com/asides/new-computer/#h-linuss-spreadsheet

    cat $1 | cut -f1 -d,;
}

addcolumn() {
    # $1: Input
    # $2: Output
    # $3: Column number
    # $4: Value

    awk -F, '{\$$3=$4 FS \$$3;}1' OFS=, $1 > $2;
}

##############
### Images ###
##############

gifdiff() {
    # req: ImageMagick
    #
    # $1: Input image 1
    # $2: Input image 2
    # $3: Output gif
    # $4: Delay between frames

    convert -delay ${4:-50} $1 $2 -loop 0 ${3:-diff.gif};
}

imgdiff() {
    # req: ImageMagick
    #
    # $1: Image file 1
    # $2: Image file 2

    compare $1 $2 -metric AE -fuzz 20% -highlight-color ${3:-red} ${4:-diff.png};
}

text2image() {
    # req: ImageMagick
    #
    # NOTE: See all fonts with `convert -list font`
    #
    # $1: Text
    # $2: Image size
    # $3: Typeface
    # $4: Font size
    # $5: Font colour
    # $6: Background colour
    # $7: Output image
    # $8: Font vertical offset (depends on typeface)

    convert \
        -size ${2:-320x125} \
        xc:"#000000" \
        -font ${3:-Impact} \
        -pointsize ${4:-64} \
        -fill white \
        -gravity center \
        -draw "text 0,${8:0} '${1:-Example}'" \
        image.png;
    }

watermark() {
    # req: ImageMagick
    #
    # $1 = input image file
    # $2 = text
    # $3 = font base colour, optional
    # $4 = font shadow colour, optional
    # $5 = typeface, optional
    # $6 = font size, optional

    convert $1 -font ${5:-Calibri} -pointsize ${6:-48} \
        -draw "gravity northeast \
        fill ${4:-black} text 150,162 $2 \
        fill ${3:-white} text 152,160 $2" \
    $1;
}

##################
### Conversion ###
##################

gif2webm() {
    # req: ffmpeg
    # cf: https://gist.github.com/ndarville/10010916

    ffmpeg -i $1 \
        -c:v libvpx \ # Video codec
        -crf 12 \
        -b:v 500K \ # Video bitrate
        $2;
}

img2gif() {
    # req: ffmpeg
    #
    # Note: You may have to use `reserve_transparent` for transparent images

    palette="/tmp/palette.png"

    ffmpeg -i $1 -vf palettegen -y $palette
    ffmpeg -i $1 -i $palette -lavfi paletteuse $2

    unset palette;

    # EXAMPLE
    ## ffmpeg -i screenshots/screenshot-%04d.png animation.gif
    ## %04d means 0000-9999; this will match screenshots/screenshots-{0000-9999}.png are matched.

}

vid2audio() {
    # req: ffmpeg
    # cf: https://trac.ffmpeg.org/wiki/audio%20types
    #
    # Note: Why to use WAV:
    # * http://www.audioanimals.co.uk/news/why-wav-is-better-than-mp3
    # * https://help.ableton.com/hc/en-us/articles/211427589-Supported-Audio-File-Formats
    # * https://www.macxdvd.com/mac-dvd-video-converter-how-to/what-is-m4a.htm
    #
    # $1: Input video
    # $2: Output name, optional

    ffmpeg -i $1 -q:a 0 -map a -c:a pcm_s32le ${2:-${1%.*}}.wav;
}

vid2gif() {
    # req: ffmpeg
    # cf: blog.pkh.me/p/21-high-quality-gif-with-ffmpeg.html
    #
    # $1: Input video
    # $2: Width, optional

    palette="/tmp/palette.png"
    filters="fps=15,scale=${2:-640}:-1:flags=lanczos"

    ffmpeg -v warning -i $1 -vf "$filters,palettegen" -y $palette
    ffmpeg -v warning -i $1 -i $palette -lavfi "$filters [x]; [x][1:v] paletteuse" -y ${1}.gif

    unset palette
    unset filters;
}

vid2mp4() {
    # req: ffmpeg
    # cf:
    # * https://gist.github.com/Vestride/278e13915894821e1d6f
    # * https://twitter.com/FFmpeg/status/943266612047577089

    ffmpeg -i $1 -vcodec h264 -acodec aac $2;
}

vid2webm() {
    # req: ffmpeg
    # cf: https://gist.github.com/Vestride/278e13915894821e1d6f

    ffmpeg -i $1 -c:v libvpx-vp9 -pass 1 -b:v 1000K -threads 1 -speed 4 \
        -tile-columns 0 -frame-parallel 0 -auto-alt-ref 1 -lag-in-frames 25 \
        -g 9999 -aq-mode 0 -an -f webm /dev/null

    ffmpeg -i $1 -c:v libvpx-vp9 -pass 2 -b:v 1000K -threads 1 -speed 0 \
        -tile-columns 0 -frame-parallel 0 -auto-alt-ref 1 -lag-in-frames 25 \
        -g 9999 -aq-mode 0 -c:a libopus -b:a 64k -f webm $2;
}

vid2webmmuted() {
    vid2webm $1 $2
    vidmute $2 $3;
}

web2png() {
    # req: web2png
    #
    # Note: Generates both thumb and full screenshot

    webkit2png --ignore-ssl-check -TF $1; # --filename or -o are optional
}

#############
### Video ###
#############

vidformat() {
    # req: ffmpeg

    ffprobe -v error -select_streams v:0 -show_entries stream=codec_name -of default=nokey=1:noprint_wrappers=1 $1;
}

vidcrop() {
    # req: ffmpeg
    # cf: trac.ffmpeg.org/wiki/Seeking
    #
    # NOTE
    ## For same codec/format
    ## Put seek times first to avoid stutter at start
    ## Use copy -c when the codec is the same
    ## Use vidfixheaders() on same file to fix duration, but might affect quality
    #
    # $1: Input video file
    # $2: Start time
    # $3: End time
    # $4: Output file name

    ffmpeg -ss $2 -i $1 -t $3 -c copy -copyts $4;
}

vidfixheaders() {
    # req: ffmpeg
    #
    # Note: has to be applied after vidcrop to fix duration metadata; otherwise breaks Twitter

    ffmpeg -analyzeduration 2148M -probesize 2148M -i $1 -c copy fixed.$1; # -f format also useful
}

vidmute() {
    # req: ffmpeg

    ffmpeg -i $1 -c copy -an $2;
}

vidscreenshotsec() {
    # req: ffmpeg
    # cf: trac.ffmpeg.org/wiki/Create%20a%20thumbnail%20image%20every%20X%20seconds%20of%20the%20video

    ffmpeg -i $1 -vf \
        fps=1 \ # 1/s
        out%04d.png; # %04d is a four-digit string
}

vidscreenshotmin() {
    # req: ffmpeg
    # cf: trac.ffmpeg.org/wiki/Create%20a%20thumbnail%20image%20every%20X%20seconds%20of%20the%20video

    ffmpeg -i $1 -vf \
        fps=1/60 \ # 1/60/s
        out%03d.png;
}

vidtile() {
    # req: ffmpeg
    # cf: https://trac.ffmpeg.org/wiki/FilteringGuide
    #
    # $1: Input video 1
    # $2: Input video 2
    # $3: Output video
    # $4: Resize width for each input video
    # $5: Tiling: h(orizontal) vs v(ertical)
    #
    # NOTE
    ## Resize to 480 width w/ auto height:
    ##     480:-1
    ## Resize to 480x200: w/ 200 height:
    ##     480:200
    ## [0:v],[1:v]:
    ##     First and second video tracks
    ## [v1],[v2]:
    ##     Variable assignment; names arbitrary chosen here
    ##     v1=[0:v] -vf scale:480:-
    ## [v1][v2]hstack[v]: Apply hstack transformation to vids 1 and 2; save as variable `v`
    ##
    ## map [v]: Grab video stream, and only video stream, (ie without audio and subtitles)
    ##
    ## Default scale is `scale:480:-1:flags=bicubic`; try lanczos sometime
    ##
    ## You can overlay text on each video with `drawtext`
    ##
    ## You can probably optimize this with palettegen+paletteuse

    STACK=${5:-h}

    ffmpeg -i $1 -i $2 -filter_complex "\
        [0:v]scale=${4:-800}:-1[v1];\
        [1:v]scale=${4:-800}:-1[v2];\
        [v1][v2]${STACK}stack[v]" \
        -map [v] \
        ${3:-comparison${1##*.}}

    unset STACK;

    # EXAMPLE
    ## ffmpeg -i foo.mp4 -i bar.mp4 -filter_complex \
    ##    "[0:v]scale=480:200[v1];[1:v]scale=480:200[v2];[v1][v2]hstack" comparison.mp4
    ## ffmpeg -i foo.mp4 -i bar.mp4 -filter_complex \
    ##    "[0:v]scale=480:200:flags=lanczos[v1];[1:v]scale=480:200:flags=lanczos[v2];[v1][v2]vstack[v]" -map [v] comparison.vertical.mp4
    ##
    ## Explicit height required since one video resized to 199px and another to 200px
}

vidstabilize() {
    # req: ffmpeg --with vid.stab or libvidstab
    # cf: scottlinux.com/2016/09/17/video-stabilization-using-vidstab-and-ffmpeg-on-linux/
    #
    # Installation: git.io/vQ0SA
    # Note: different scripts depending on shakiness; this one is for max shakiness
    #
    # $1: Input video file
    # $2: Shakiness, optional; takes values 1-10; default is 10
    # $3: transforms.crf calibration file path, optional

    ffmpeg -i $1 -vf vidstabdetect=results=${3:-"transforms.crf"}:shakiness=${2:-10}:accuracy=15 -f null -
    ffmpeg -i $1 -vf vidstabtransform=smoothing=30:input=${3:-"transforms.crf"} stable.$1
    rm ${3:"transforms.crf"};
}

############
### Misc ###
############

getsubsource() {
    # Note
    ## Generates subsource integrity string for file
    ## `integrity` works as a checksum to validate externally loaded scripts
    ## If you must use external CDN JS, always use versioning

    # eg
    ## wget -q https://cdn.example.com/foo/1.3/foo.min.js
    ##
    ## <script <!-- or <link -->
    ##     src="https://cdn.example.com/foo/1.3/foo.min.js"
    ##     integrity="sha384-{{getsubresource foo.min.js}}"
    ##     crossorigin="anonymous"></script>

    cat $1 |
    openssl dgst -sha384 -binary |
    openssl enc -base64 -A;
}

stripmetadata() {
    # req: exiftool

    exiftool -v3 -all:all= $1;
}
